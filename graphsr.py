# -*- coding: utf-8 -*-
"""GraphSR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12ARgFv7YzVQUN5qaZYYa0GKXm1ml2k8n
"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data
from torch_geometric.utils import add_self_loops, degree
import numpy as np


class GraphSR(torch.nn.Module):
  def __init__(self, in_channels, hidden_channels, out_channels):
    super(GraphSR, self).__init__()
    self.conv1 = GCNConv(in_channels, hidden_channels)
    self.conv2 = GCNConv(hidden_channels, out_channels)

  def forward(self, x, edge_index):
    x = self.conv1(x, edge_index)
    x = F.relu(x)
    x = self.conv2(x, edge_index)
    return F.log_softmax(x, dim=1)

  def augment_data(data, num_augments=5):
    augmented_data_list = []
    for _ in range(num_augments):
      edge_index, _ = add_self_loops(data.edge_index, num_nodes=data.num_nodes)
      row, col = edge_index
      deg = degree(col, data.num_nodes, dtype=torch.float)
      deg_inv_sqrt = deg.pow(-0.5)
      norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]
      edge_index = edge_index[:, torch.randperm(edge_index.size(1))]
      augmented_data = Data(x=data.x, edge_index=edge_index, y=data.y)
      augmented_data_list.append(augmented_data)
    return augmented_data_list


  def train(model, data, optimizer, criterion):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

  def evaluate(model, data):
    model.eval()
    with torch.no_grad():
      out = model(data.x, data.edge_index)
      pred = out.argmax(dim=1)
      correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()
      acc = int(correct) / int(data.test_mask.sum())
    return acc


  def main():
    num_nodes = 100
    num_features = 16
    num_classes = 3
    x = torch.randn((num_nodes, num_features))
    edge_index = torch.randint(0, num_nodes, (2, 500))
    y = torch.randint(0, num_classes, (num_nodes,))
    train_mask = torch.zeros(num_nodes, dtype=torch.bool).bernoulli(0.8)
    test_mask = ~train_mask
    data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)
    augmented_data_list = augmented_data(data)

    # Initialize model, optimizer, and loss function
    model = GraphSR(in_channels=num_features, hidden_channels=32, out_channels=num_classes)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    criterion = torch.nn.CrossEntropyLoss()
    # Train and evaluate the model

    for epoch in range(1, 201):
      for augmented_data in augmented_data_list:
        loss = train(model, augmented_data, optimizer, criterion)
        if epoch % 10 == 0:
          acc = evaluate(model, data)
          print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')

    if __name__ == "__main__":
      main()

"""## RU-Selection Using GNN"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.data import Data
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import random


class GCN(torch.nn.Module):
  def __init__(self, in_channels, hidden_channels, out_channels):
    super(GCN, self).__init__()
    self.conv1 = GCNConv(in_channels, hidden_channels)
    self.conv2 = GCNConv(hidden_channels, out_channels)

  def forward(self, x, edge_index):
    x = self.conv1(x, edge_index)
    x = F.relu(x)
    x = self.conv2(x, edge_index)
    return F.log_softmax(x, dim=1)

#Define RU-Selection Class
class RUSelection:
  def __init__(self, model, data, minority_class, device='cpu'):
    self.model = model
    self.data = data
    self.minority_class = minority_class
    self.device = device

  def supplement_minority_class(self):
    self.model.eval()
    with torch.no_grad():
      out = self.model(self.data.x.to(self.device), self.data.edge_index.to(self.device))
      pseudo_labels = out.argmax(dim=1).cpu()

    minority_indices = (pseudo_labels == self.minority_class).nonzero(as_tuple=True)[0]
    labelled_indices = self.data.train_mask.nonzero(as_tuple=True)[0]
    minority_count = (self.data.y[labelled_indices] == self.minority_class).sum().item()

    while minority_count < len(labelled_indices) / len(torch.unique(self.data.y)):
      random_index = random.choice(minority_indices)
      if not self.data.train_mask[random_index]:
        self.data.train_mask[random_index] = True
        self.data.y[random_index] = self.minority_class
        minority_count += 1
      return self.data

#Define SU-Selection Class
class SUSelection:
  def __init__(self, model, data, minority_class, device='cpu'):
    self.model = model
    self.data = data
    self.minority_class = minority_class
    self.device = device

  def supplement_minority_class(self):
    self.model.eval()
    with torch.no_grad():
      out = self.model(self.data.x.to(self.device), self.data.edge_index.to(self.device))
    pseudo_labels = out.argmax(dim=1).cpu()

    minority_indices = (pseudo_labels == self.minority_class).nonzero(as_tuple=True)[0]
    labelled_indices = self.data.train_mask.nonzero(as_tuple=True)[0]
    minority_count = (self.data.y[labelled_indices] == self.minority_class).sum().item()

    similarities = cosine_similarity(self.data.x[minority_indices], self.data.x[labelled_indices])
    sorted_indices = np.argsort(-similarities, axis=1)

    while minority_count < len(labelled_indices) / len(torch.unique(self.data.y)):
      for idx in sorted_indices:
        for similar_idx in idx:
          if not self.data.train_mask[minority_indices[similar_idx]]:
            self.data.train_mask[minority_indices[similar_idx]] = True
            self.data.y[minority_indices[similar_idx]] = self.minority_class
            minority_count += 1
            break
            if minority_count >= len(labelled_indices) / len(torch.unique(self.data.y)):
              break

          return self.data

def main():
  num_nodes = 100
  num_features = 16
  num_classes = 3
  x = torch.randn((num_nodes, num_features))
  edge_index = torch.randint(0, num_nodes, (2, 500))
  y = torch.randint(0, num_classes, (num_nodes,))
  train_mask = torch.zeros(num_nodes, dtype=torch.bool).bernoulli(0.8)
  test_mask = ~train_mask
  data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)
  # Initialize model
  model = GCN(in_channels=num_features, hidden_channels=32, out_channels=num_classes)
  model = model.to('cpu')

  # RU-Selection
  ru_selection = RUSelection(model, data, minority_class=1, device='cpu')
  data = ru_selection.supplement_minority_class()

  # SU-Selection
  su_selection = SUSelection(model, data, minority_class=1, device='cpu')
  data = su_selection.supplement_minority_class()

  # Train and evaluate the model (example)
  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
  criterion = torch.nn.CrossEntropyLoss()

  for epoch in range(1, 201):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

  if epoch % 10 == 0:
    model.eval()
    with torch.no_grad():
      out = model(data.x, data.edge_index)
      pred = out.argmax(dim=1)
      correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()
      acc = int(correct) / int(data.test_mask.sum())
  print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')
  if __name__ == "__main__":
    main()

"""## SU-Selection Using GNN"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import SAGEConv
from torch_geometric.data import Data
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import random


class GraphSAGE(torch.nn.Module):
  def __init__(self, in_channels, hidden_channels, out_channels):
    super(GraphSAGE, self).__init__()
    self.conv1 = SAGEConv(in_channels, hidden_channels)
    self.conv2 = SAGEConv(hidden_channels, out_channels)

  def forward(self, x, edge_index):
    x = self.conv1(x, edge_index)
    x = F.relu(x)
    x = self.conv2(x, edge_index)
    return F.log_softmax(x, dim=1)


class RUSelection:
  def __init__(self, model, data, minority_class, device='cpu'):
    self.model = model
    self.data = data
    self.minority_class = minority_class
    self.device = device

  def supplement_minority_class(self):
    self.model.eval()
    with torch.no_grad():
      out = self.model(self.data.x.to(self.device), self.data.edge_index.to(self.device))
    pseudo_labels = out.argmax(dim=1).cpu()

    minority_indices = (pseudo_labels == self.minority_class).nonzero(as_tuple=True)[0]
    labelled_indices = self.data.train_mask.nonzero(as_tuple=True)[0]
    minority_count = (self.data.y[labelled_indices] == self.minority_class).sum().item()

    while minority_count < len(labelled_indices) / len(torch.unique(self.data.y)):
      random_index = random.choice(minority_indices)
      if not self.data.train_mask[random_index]:
        self.data.train_mask[random_index] = True
        self.data.y[random_index] = self.minority_class
      minority_count += 1
      return self.data


class SUSelection:
  def __init__(self, model, data, minority_class, device='cpu'):
    self.model = model
    self.data = data
    self.minority_class = minority_class
    self.device = device

  def supplement_minority_class(self):
    self.model.eval()
    with torch.no_grad():
      out = self.model(self.data.x.to(self.device), self.data.edge_index.to(self.device))
      pseudo_labels = out.argmax(dim=1).cpu()

    minority_indices = (pseudo_labels == self.minority_class).nonzero(as_tuple=True)[0]
    labelled_indices = self.data.train_mask.nonzero(as_tuple=True)[0]
    minority_count = (self.data.y[labelled_indices] == self.minority_class).sum().item()

    similarities = cosine_similarity(self.data.x[minority_indices], self.data.x[labelled_indices])
    sorted_indices = np.argsort(-similarities, axis=1)

    while minority_count < len(labelled_indices) / len(torch.unique(self.data.y)):
      for idx in sorted_indices:
        for similar_idx in idx:
          if not self.data.train_mask[minority_indices[similar_idx]]:
            self.data.train_mask[minority_indices[similar_idx]] = True
            self.data.y[minority_indices[similar_idx]] = self.minority_class
      minority_count += 1
      break
      if minority_count >= len(labelled_indices) / len(torch.unique(self.data.y)):
        break

        return self.data


def main():
  num_nodes = 100
  num_features = 16
  num_classes = 3
  x = torch.randn((num_nodes, num_features))
  edge_index = torch.randint(0, num_nodes, (2, 500))
  y = torch.randint(0, num_classes, (num_nodes,))
  train_mask = torch.zeros(num_nodes, dtype=torch.bool).bernoulli(0.8)
  test_mask = ~train_mask
  data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)

  # Initialize model
  model = GraphSAGE(in_channels=num_features, hidden_channels=32, out_channels=num_classes)
  model = model.to('cpu')

  # RU-Selection
  ru_selection = RUSelection(model, data, minority_class=1, device='cpu')
  data = ru_selection.supplement_minority_class()

  # SU-Selection
  su_selection = SUSelection(model, data, minority_class=1, device='cpu')
  data = su_selection.supplement_minority_class()

  # Train and evaluate the model (example)
  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
  criterion = torch.nn.CrossEntropyLoss()

  for epoch in range(1, 201):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

    if epoch % 10 == 0:
      model.eval()
      with torch.no_grad():
        out = model(data.x, data.edge_index)
        pred = out.argmax(dim=1)
        correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()
        acc = int(correct) / int(data.test_mask.sum())
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')
    if __name__ == "__main__":
      main()

"""## Imbalance ratio for RU-Selection, Su-Selection, and GraphSR"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import SAGEConv, GCNConv
from torch_geometric.data import Data
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import random


def supplement_minority_class(self):
  self.model.eval()
  with torch.no_grad():
    out = self.model(self.data.x.to(self.device), self.data.edge_index.to(self.device))
    pseudo_labels = out.argmax(dim=1).cpu()

  minority_indices = (pseudo_labels == self.minority_class).nonzero(as_tuple=True)[0]
  labelled_indices = self.data.train_mask.nonzero(as_tuple=True)[0]
  minority_count = (self.data.y[labelled_indices] == self.minority_class).sum().item()

  while minority_count < len(labelled_indices) / len(torch.unique(self.data.y)):
    random_index = random.choice(minority_indices)
    if not self.data.train_mask[random_index]:
      self.data.train_mask[random_index] = True
      self.data.y[random_index] = self.minority_class
    minority_count += 1

    return self.data


def supplement_minority_class(self):
  self.model.eval()
  with torch.no_grad():
    out = self.model(self.data.x.to(self.device), self.data.edge_index.to(self.device))
    pseudo_labels = out.argmax(dim=1).cpu()

  minority_indices = (pseudo_labels == self.minority_class).nonzero(as_tuple=True)[0]
  labelled_indices = self.data.train_mask.nonzero(as_tuple=True)[0]
  minority_count = (self.data.y[labelled_indices] == self.minority_class).sum().item()

  similarities = cosine_similarity(self.data.x[minority_indices], self.data.x[labelled_indices])
  sorted_indices = np.argsort(-similarities, axis=1)

  while minority_count < len(labelled_indices) / len(torch.unique(self.data.y)):
    for idx in sorted_indices:
      for similar_idx in idx:
        if not self.data.train_mask[minority_indices[similar_idx]]:
          self.data.train_mask[minority_indices[similar_idx]] = True
          self.data.y[minority_indices[similar_idx]] = self.minority_class
        minority_count += 1
        break
        if minority_count >= len(labelled_indices) / len(torch.unique(self.data.y)):
          break
          return self.data

#Define Imbalance Ratio Calculation
def calculate_imbalance_ratio(data):
  class_counts = torch.bincount(data.y[data.train_mask])
  imbalance_ratio = class_counts.max().item() / class_counts.min().item()
  return imbalance_ratio


def main():
  num_nodes = 100
  num_features = 16
  num_classes = 3
  x = torch.randn((num_nodes, num_features))
  edge_index = torch.randint(0, num_nodes, (2, 500))
  y = torch.randint(0, num_classes, (num_nodes,))
  train_mask = torch.zeros(num_nodes, dtype=torch.bool).bernoulli(0.8)
  test_mask = ~train_mask

  data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)
  sage_model = GraphSAGE(in_channels=num_features, hidden_channels=32, out_channels=num_classes)
  sr_model = GraphSR(in_channels=num_features, hidden_channels=32, out_channels=num_classes)
  sage_model = sage_model.to('cpu')
  sr_model = sr_model.to('cpu')

  # RU-Selection
  ru_selection = RUSelection(sage_model, data, minority_class=1, device='cpu')
  data = ru_selection.supplement_minority_class()

  # SU-Selection
  su_selection = SUSelection(sage_model, data, minority_class=1, device='cpu')
  data = su_selection.supplement_minority_class()

  # Calculate imbalance ratio
  imbalance_ratio = calculate_imbalance_ratio(data)
  print(f'Imbalance Ratio: {imbalance_ratio:.4f}')

  # Train and evaluate the model (example)
  optimizer = torch.optim.Adam(sage_model.parameters(), lr=0.01)
  criterion = torch.nn.CrossEntropyLoss()

  for epoch in range(1, 201):
    sage_model.train()
    optimizer.zero_grad()
    out = sage_model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

  if epoch % 10 == 0:
    sage_model.eval()
    with torch.no_grad():
      out = sage_model(data.x, data.edge_index)
      pred = out.argmax(dim=1)
      correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()
      acc = int(correct) / int(data.test_mask.sum())
      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')

  if __name__ == "__main__":
    main()